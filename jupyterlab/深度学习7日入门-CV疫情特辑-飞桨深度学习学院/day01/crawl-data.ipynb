{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import requests\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.date.today().strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_dxy_data():\n",
    "    \"\"\"\n",
    "    爬取丁香园实时统计数据，保存到data目录下，以当前日期作为文件名，存JSON文件\n",
    "    \"\"\"\n",
    "    response = requests.get('https://ncov.dxy.cn/ncovh5/view/pneumonia') #request.get()用于请求目标网站\n",
    "    print(response.status_code)                                          # 打印状态码\n",
    "\n",
    "    try:\n",
    "        url_text = response.content.decode()                             #更推荐使用response.content.deocde()的方式获取响应的html页面\n",
    "        #print(url_text)\n",
    "        url_content = re.search(r'window.getAreaStat = (.*?)}]}catch',   #re.search():扫描字符串以查找正则表达式模式产生匹配项的第一个位置 ，然后返回相应的match对象。\n",
    "                                url_text, re.S)                          #在字符串a中，包含换行符\\n，在这种情况下：如果不使用re.S参数，则只在每一行内进行匹配，如果一行没有，就换下一行重新开始;\n",
    "                                                                         #而使用re.S参数以后，正则表达式会将这个字符串作为一个整体，在整体中进行匹配。\n",
    "        texts = url_content.group()                                      #获取匹配正则表达式的整体结果\n",
    "        content = texts.replace('window.getAreaStat = ', '').replace('}catch', '') #去除多余的字符\n",
    "        json_data = json.loads(content)                                         \n",
    "        with open('./data/' + today + '.json', 'w', encoding='UTF-8') as f:\n",
    "            json.dump(json_data, f, ensure_ascii=False)\n",
    "    except:\n",
    "        print('<Response [%s]>' % response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_statistics_data():\n",
    "    \"\"\"\n",
    "    获取各个省份历史统计数据，保存到data目录下，存JSON文件\n",
    "    \"\"\"\n",
    "    with open('./data/'+ today + '.json', 'r', encoding='UTF-8') as file:\n",
    "        json_array = json.loads(file.read())\n",
    "\n",
    "    statistics_data = {}\n",
    "    for province in json_array:\n",
    "        response = requests.get(province['statisticsData'])\n",
    "        try:\n",
    "            statistics_data[province['provinceShortName']] = json.loads(response.content.decode())['data']\n",
    "        except:\n",
    "            print('<Response [%s]> for url: [%s]' % (response.status_code, province['statisticsData']))\n",
    "\n",
    "    with open(\"./data/statistics_data.json\", \"w\", encoding='UTF-8') as f:\n",
    "        json.dump(statistics_data, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "200\n"
    }
   ],
   "source": [
    "crawl_dxy_data()\n",
    "crawl_statistics_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}